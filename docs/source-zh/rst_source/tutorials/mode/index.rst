灵活的执行模式
========================

传统的 RL 后训练系统通常根据其 GPU 部署策略分为两种主要模式：:doc:`collocated` 和 :doc:`disaggregated`。

在 **共享式** 模式下，所有主要组件（如 generator、actor inference 和 actor training）共享同一组 GPU 或节点。  
相反，在 **分离式** 模式下，这些组件会被分配到不同的 GPU 或节点。

然而，这两种模式都不太适合复杂的 RL 工作负载，例如具身智能任务，因为这类任务涉及更多的组件（如 simulators）和更复杂的通信模式 —— 例如 **simulator** 和 **generator** 之间的细粒度交互。

为了更好地支持多样化和动态的 RL 工作负载，**RLinf** 提供了灵活的组件部署和执行模式，  
允许用户以高度可配置的方式调度组件。特别地，组件可以部署在 **任意 GPU** 上，并结合不同的执行策略：

- **部署在相同 GPU 上（共享式**：  
  用户可以配置两个组件是否同时常驻 GPU 显存，  
  或者通过卸载/重新加载机制交替使用 GPU。

- **部署在不同 GPU 上（分离式**：  
  组件可以顺序运行（可能导致 GPU 空闲），  
  也可以采用流水线方式执行，以确保所有 GPU 都保持忙碌状态。

**混合式** 模式进一步扩展了这种灵活性，  
支持对部署与执行策略进行自定义组合。

.. toctree::
   :hidden:
   :maxdepth: 1

   collocated
   disaggregated
   hybrid
