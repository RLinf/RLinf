name: Math End2End

on:
    push:
        branches: [ main, v[0-9].[0-9], feat/ci ]
        paths:
          - '**/*.py'
          - '!docs/**'
          - 'README.md'
          - '*.yaml'
          - '*.toml'

    pull_request:
        branches: [ main, v[0-9].[0-9], feat/ci ]
        paths:
          - '**/*.py'
          - '!docs/**'
          - 'README.md'
          - '*.yaml'
          - '*.toml'

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
    qwen-grpo-test:
        runs-on: self-hosted
        container:
            image: beijing-j.cr.infini-ai.com:32443/te-dbdcudoygepmq5vx/rlsys:v2.4
            volumes:
                - /mnt/public/dataset:/workspace/dataset
                - /mnt/public/tokenizer:/workspace/tokenizer
            options: --gpus="all" --shm-size=80g

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Install Megatron
              run: git clone https://github.com/NVIDIA/Megatron-LM.git -b v0.11.0 megatron

            - name: Collocated mode
              run: |
                export REPO_PATH=$(pwd)
                bash tests/e2e_tests/math/run_collocated.sh

            - name: Pipeline mode
              run: |
                export REPO_PATH=$(pwd)
                bash tests/e2e_tests/math/run_pipeline.sh